#!/usr/bin/env python3
"""
Distributed Sync Coordinator
============================

Implements the distributed sync worker system as originally planned in
distributed_sync_architecture.md

Features:
- Task queue coordination via PostgreSQL
- Collection chunking for large datasets
- Worker health monitoring and coordination
- Scalable sync processing (1K to 10M+ documents)
"""

import psycopg2
import requests
import time
import uuid
import json
from datetime import datetime, timedelta
from typing import List, Dict, Optional

class DistributedSyncCoordinator:
    def __init__(self):
        self.connection_string = 'postgresql://chroma_user:xqIF9T5U6LhySuSw86JqWYf7qtyGDXy8@dpg-d16mkandiees73db52u0-a.oregon-postgres.render.com/chroma_ha'
        self.primary_url = 'https://chroma-primary.onrender.com'
        self.replica_url = 'https://chroma-replica.onrender.com'
        self.coordinator_id = f"coordinator_{uuid.uuid4().hex[:8]}"
        
    def get_db_connection(self):
        return psycopg2.connect(self.connection_string)
    
    def get_collections_with_counts(self) -> List[Dict]:
        """Get all collections with document counts from both instances"""
        collections = []
        
        try:
            # Get collections from primary
            primary_response = requests.get(
                f"{self.primary_url}/api/v2/tenants/default_tenant/databases/default_database/collections",
                timeout=15
            )
            
            if primary_response.status_code == 200:
                primary_collections = primary_response.json()
                
                for collection in primary_collections:
                    collection_id = collection['id']
                    collection_name = collection['name']
                    
                    # Get document counts
                    primary_count = self.get_document_count(collection_id, 'primary')
                    replica_count = self.get_document_count(collection_id, 'replica')
                    
                    collections.append({
                        'id': collection_id,
                        'name': collection_name,
                        'primary_count': primary_count or 0,
                        'replica_count': replica_count or 0,
                        'needs_sync': (primary_count or 0) != (replica_count or 0)
                    })
                    
        except Exception as e:
            print(f"âŒ Error getting collections: {e}")
            
        return collections
    
    def get_document_count(self, collection_id: str, instance: str) -> Optional[int]:
        """Get document count for a collection on specific instance"""
        try:
            base_url = self.primary_url if instance == 'primary' else self.replica_url
            response = requests.get(
                f"{base_url}/api/v2/tenants/default_tenant/databases/default_database/collections/{collection_id}/count",
                timeout=10
            )
            if response.status_code == 200:
                return response.json()
            return None
        except:
            return None
    
    def create_sync_tasks(self, collection: Dict) -> int:
        """Create sync tasks for a collection that needs synchronization"""
        chunk_size = 1000  # Documents per chunk
        doc_count = max(collection['primary_count'], collection['replica_count'])
        
        if doc_count == 0:
            return 0
            
        tasks_created = 0
        
        try:
            with self.get_db_connection() as conn:
                with conn.cursor() as cur:
                    
                    # Create chunks based on document count
                    for start_offset in range(0, doc_count, chunk_size):
                        end_offset = min(start_offset + chunk_size, doc_count)
                        
                        cur.execute("""
                            INSERT INTO sync_tasks 
                            (collection_id, collection_name, chunk_start_offset, chunk_end_offset, 
                             task_status, created_at)
                            VALUES (%s, %s, %s, %s, 'pending', NOW())
                        """, (
                            collection['id'],
                            collection['name'],
                            start_offset,
                            end_offset,
                            'pending'
                        ))
                        tasks_created += 1
                    
                    conn.commit()
                    
        except Exception as e:
            print(f"âŒ Error creating sync tasks: {e}")
            return 0
            
        return tasks_created
    
    def update_collection_sync_state(self, collection: Dict):
        """Update the sync_collections table with current state"""
        try:
            with self.get_db_connection() as conn:
                with conn.cursor() as cur:
                    
                    sync_status = 'success' if not collection['needs_sync'] else 'pending'
                    sync_lag = abs(collection['primary_count'] - collection['replica_count'])
                    
                    cur.execute("""
                        INSERT INTO sync_collections 
                        (collection_id, collection_name, primary_document_count, replica_document_count,
                         sync_status, sync_lag_seconds, last_sync_attempt, updated_at)
                        VALUES (%s, %s, %s, %s, %s, %s, NOW(), NOW())
                        ON CONFLICT (collection_id)
                        DO UPDATE SET 
                            primary_document_count = EXCLUDED.primary_document_count,
                            replica_document_count = EXCLUDED.replica_document_count,
                            sync_status = EXCLUDED.sync_status,
                            sync_lag_seconds = EXCLUDED.sync_lag_seconds,
                            last_sync_attempt = NOW(),
                            updated_at = NOW()
                    """, (
                        collection['id'],
                        collection['name'],
                        collection['primary_count'],
                        collection['replica_count'],
                        sync_status,
                        sync_lag * 2  # Estimate 2 seconds per document lag
                    ))
                    
                    conn.commit()
                    
        except Exception as e:
            print(f"âŒ Error updating collection sync state: {e}")
    
    def register_worker(self, worker_id: str):
        """Register a sync worker in the coordination system"""
        try:
            with self.get_db_connection() as conn:
                with conn.cursor() as cur:
                    cur.execute("""
                        INSERT INTO sync_workers (worker_id, last_heartbeat, worker_status)
                        VALUES (%s, NOW(), 'active')
                        ON CONFLICT (worker_id)
                        DO UPDATE SET last_heartbeat = NOW(), worker_status = 'active'
                    """, (worker_id,))
                    conn.commit()
                    print(f"âœ… Registered worker: {worker_id}")
        except Exception as e:
            print(f"âŒ Error registering worker: {e}")
    
    def run_coordination_cycle(self):
        """Run one cycle of sync coordination"""
        print(f"ğŸš€ DISTRIBUTED SYNC COORDINATION CYCLE")
        print(f"   Coordinator: {self.coordinator_id}")
        print(f"   Time: {datetime.now()}")
        print("=" * 50)
        
        # Get all collections and their sync status
        collections = self.get_collections_with_counts()
        
        if not collections:
            print("âŒ No collections found")
            return
            
        print(f"ğŸ“Š COLLECTION SYNC ANALYSIS:")
        total_tasks_created = 0
        collections_needing_sync = 0
        
        for collection in collections:
            name = collection['name']
            primary_count = collection['primary_count']
            replica_count = collection['replica_count']
            needs_sync = collection['needs_sync']
            
            status_icon = "âš ï¸" if needs_sync else "âœ…"
            print(f"   {status_icon} {name}: Primary={primary_count}, Replica={replica_count}")
            
            # Update collection sync state
            self.update_collection_sync_state(collection)
            
            # Create sync tasks if needed
            if needs_sync:
                tasks_created = self.create_sync_tasks(collection)
                total_tasks_created += tasks_created
                collections_needing_sync += 1
                print(f"      ğŸ“‹ Created {tasks_created} sync tasks")
        
        print(f"\nğŸ“ˆ COORDINATION RESULTS:")
        print(f"   Collections analyzed: {len(collections)}")
        print(f"   Collections needing sync: {collections_needing_sync}")
        print(f"   Sync tasks created: {total_tasks_created}")
        
        # Register this coordinator as a worker
        self.register_worker(self.coordinator_id)
        
        print(f"\nâœ… COORDINATION CYCLE COMPLETED!")
        
        return {
            'total_collections': len(collections),
            'collections_needing_sync': collections_needing_sync,
            'tasks_created': total_tasks_created
        }

if __name__ == "__main__":
    coordinator = DistributedSyncCoordinator()
    
    print("ğŸ—ï¸  DISTRIBUTED SYNC COORDINATOR")
    print("Based on: distributed_sync_architecture.md")
    print("=" * 50)
    
    response = input("ğŸš€ Run sync coordination cycle? (yes/no): ")
    if response.lower() in ['yes', 'y']:
        results = coordinator.run_coordination_cycle()
        
        if results['tasks_created'] > 0:
            print(f"\nğŸ¯ NEXT STEPS:")
            print(f"   â€¢ Deploy sync workers to process {results['tasks_created']} tasks")
            print(f"   â€¢ Workers will coordinate via PostgreSQL task queue")
            print(f"   â€¢ System scales from 1K to 10M+ documents")
        else:
            print(f"\nğŸ‰ ALL COLLECTIONS IN SYNC!")
            print(f"   â€¢ No sync tasks needed")
            print(f"   â€¢ System is operating optimally")
    else:
        print("âŒ Coordination cancelled.") 